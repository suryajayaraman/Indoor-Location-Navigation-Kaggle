{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-species",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liable-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# metrics calculation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# basic plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# interactive plots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-solution",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "green-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # pipeline parameters\n",
    "    SEED        = 42\n",
    "    TRAIN       = True\n",
    "    LR_FIND     = False\n",
    "    TEST        = False\n",
    "    N_FOLDS     = 5 \n",
    "    N_EPOCHS    = 50\n",
    "    TEST_BATCH_SIZE  = 32\n",
    "    TRAIN_BATCH_SIZE = 16\n",
    "    NUM_WORKERS      = 4\n",
    "    DATA_FRAC        = 1.0\n",
    "    FOLD_TO_TRAIN    = [0, 1, 2, 3, 4] # \n",
    "\n",
    "    # model parameters\n",
    "    MODEL_ARCH  = 'MLP'\n",
    "    MODEL_NAME  = 'mlp_v3'\n",
    "    WGT_PATH    = ''\n",
    "    WGT_MODEL   = ''\n",
    "    PRINT_N_EPOCH = 2\n",
    "    \n",
    "    # scheduler variables\n",
    "    MAX_LR    = 1e-2\n",
    "    MIN_LR    = 1e-4\n",
    "    SCHEDULER = 'CosineAnnealingWarmRestarts'  # ['ReduceLROnPlateau', 'None', OneCycleLR', ','CosineAnnealingLR']\n",
    "    T_0       = 10     # CosineAnnealingWarmRestarts\n",
    "    T_MULT    = 2      # CosineAnnealingWarmRestarts\n",
    "    T_MAX     = 2.5    # CosineAnnealingLR\n",
    "\n",
    "    # optimizer variables\n",
    "    OPTIMIZER     = 'Adam'\n",
    "    WEIGHT_DECAY  = 1e-6\n",
    "    GRD_ACC_STEPS = 1\n",
    "    MAX_GRD_NORM  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "timely-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5a0546857ecc773753327266_train.csv']\n"
     ]
    }
   ],
   "source": [
    "floor_map = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\n",
    "             \"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n",
    "\n",
    "minCount = 1\n",
    "rssiFillerValue = -999.0\n",
    "dtFillerValue   = 1000.0\n",
    "freqFillerValue = 0\n",
    "outputDir = 'referencePublicNotebooks/wiFiFeatures'\n",
    "modelOutputDir = 'modelSaveDir'\n",
    "sampleCsvPath = 'sample_submission.csv'\n",
    "\n",
    "buildingsList = glob.glob(f\"{outputDir}/*.csv\")\n",
    "print([x.split('/')[-1] for x in buildingsList])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-market",
   "metadata": {
    "papermill": {
     "duration": 0.030885,
     "end_time": "2021-02-15T09:18:40.779692",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.748807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuildingName(buildingCsvPath):\n",
    "    fileName = buildingCsvPath.split('/')[-1]\n",
    "    buildingName = fileName.rstrip('_train.csv')\n",
    "    return buildingName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loved-theme",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:40.849777Z",
     "iopub.status.busy": "2021-02-15T09:18:40.847758Z",
     "iopub.status.idle": "2021-02-15T09:18:40.850551Z",
     "shell.execute_reply": "2021-02-15T09:18:40.851077Z"
    },
    "papermill": {
     "duration": 0.040621,
     "end_time": "2021-02-15T09:18:40.851226",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.810605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjustable-shower",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:40.921617Z",
     "iopub.status.busy": "2021-02-15T09:18:40.920714Z",
     "iopub.status.idle": "2021-02-15T09:18:40.927627Z",
     "shell.execute_reply": "2021-02-15T09:18:40.926924Z"
    },
    "papermill": {
     "duration": 0.045466,
     "end_time": "2021-02-15T09:18:40.927741",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.882275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "political-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitionMetric(preds, targets):\n",
    "    \"\"\" The metric used in this competition \"\"\"\n",
    "    # position error\n",
    "    meanPosPredictionError = torch.mean(torch.sqrt(\n",
    "                             torch.square(torch.subtract(preds[:,0], targets[:,0])) + \n",
    "                             torch.square(torch.subtract(preds[:,1], targets[:,1]))))\n",
    "    # error in floor prediction\n",
    "    meanFloorPredictionError = torch.mean(15 * torch.abs(preds[:,2] - targets[:,2]))\n",
    "    return meanPosPredictionError, meanFloorPredictionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "empirical-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimizer(model : nn.Module):    \n",
    "    if CFG.OPTIMIZER == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR, momentum=0.9)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chronic-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScheduler(optimizer, dataloader_train):\n",
    "    if CFG.SCHEDULER == 'OneCycleLR':\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr= CFG.MAX_LR, epochs = CFG.N_EPOCHS, \n",
    "                          steps_per_epoch = len(dataloader_train), pct_start=0.25, div_factor=10, anneal_strategy='cos')\n",
    "    elif CFG.SCHEDULER == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=CFG.T_MULT, eta_min=CFG.MIN_LR, last_epoch=-1)\n",
    "    elif CFG.SCHEDULER == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_MAX * len(dataloader_train), eta_min=CFG.MIN_LR, last_epoch=-1)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opposed-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuildingData(buildingCsvPath):\n",
    "    # read building data \n",
    "    data = pd.read_csv(buildingCsvPath)\n",
    "    \n",
    "    # use fraction if needed\n",
    "    if CFG.DATA_FRAC < 1:\n",
    "        data = data.sample(frac=CFG.DATA_FRAC).reset_index(drop=True)\n",
    "\n",
    "    \"\"\"\n",
    "    Incase freq signal is not needed\n",
    "    \n",
    "    # There are 4 columns for y values in csv, reamining are features\n",
    "    # total features = 3 * [rssi, dt, freq]\n",
    "    # hence unique wifi ids = totalFeatures / 3\n",
    "    # numWiFiIds = int((data.shape[1] - 4) / 3)\n",
    "    \n",
    "    # separate into features and target variables\n",
    "    X = data.iloc[:,0:(2*numWiFiIds)].values    \n",
    "    \"\"\"\n",
    "    \n",
    "    X = data.iloc[:,0:-4].values    \n",
    "    y = data.iloc[:,-4:-1].values\n",
    "    groups = data.iloc[:,-1].values\n",
    "    del data\n",
    "    gc.collect()\n",
    "    return X,y, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handy-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingResults(resultsDf):\n",
    "    # subplot to plot\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    colors = [ ('#d32f2f', '#ef5350'), ('#303f9f', '#5c6bc0'), ('#00796b', '#26a69a'),\n",
    "                ('#fbc02d', '#ffeb3b'), ('#5d4037', '#8d6e63')]\n",
    "\n",
    "    # find number of folds input df\n",
    "    numberOfFolds = resultsDf['fold'].nunique()\n",
    "    \n",
    "    # iterate through folds and plot\n",
    "    for i in range(numberOfFolds):\n",
    "        data = df[df['fold'] == i]\n",
    "        fig.add_trace(go.Scatter(x=data['epoch'].values, y=data['trainPosLoss'].values,\n",
    "                                mode='lines', visible='legendonly' if i > 0 else True,\n",
    "                                line=dict(color=colors[i][0], width=2),\n",
    "                                name='trainPossLoss -Fold{}'.format(i)),row=1, col=1)\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=data['epoch'], y=data['valPosLoss'].values,\n",
    "                                 mode='lines+markers', visible='legendonly' if i > 0 else True,\n",
    "                                 line=dict(color=colors[i][1], width=2),\n",
    "                                 name='valPosLoss -Fold{}'.format(i)),row=1, col=1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-patrick",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "special-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiFiFeaturesDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data, transform=None):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.from_numpy(self.X_data[index].astype(np.float32))\n",
    "        y = torch.from_numpy(self.y_data[index].astype(np.float32))\n",
    "        return x,y\n",
    "        #return self.X_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-marriage",
   "metadata": {},
   "source": [
    "## MLP Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spanish-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiFiFeaturesMLPModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_features=n_input, out_features=512)\n",
    "        self.lin2 = nn.Linear(in_features=512,     out_features=32)\n",
    "        self.lin3 = nn.Linear(in_features=32,      out_features=n_output)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.drops = nn.Dropout(0.3)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-algeria",
   "metadata": {},
   "source": [
    "## Compute Device as CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lightweight-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Device as cpu or tpu\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-liver",
   "metadata": {},
   "source": [
    "## Preprocessing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proof-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cv\n",
    "folds = GroupKFold(n_splits=CFG.N_FOLDS)\n",
    "\n",
    "# for normalizing input data\n",
    "stdScaler = StandardScaler()\n",
    "\n",
    "# scaler to handle AMP\n",
    "scaler = GradScaler()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-relaxation",
   "metadata": {},
   "source": [
    "## Lr range finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "advised-trustee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:43.043751Z",
     "iopub.status.busy": "2021-02-15T09:18:43.041644Z",
     "iopub.status.idle": "2021-02-15T09:18:43.044555Z",
     "shell.execute_reply": "2021-02-15T09:18:43.045101Z"
    },
    "papermill": {
     "duration": 0.044791,
     "end_time": "2021-02-15T09:18:43.045246",
     "exception": false,
     "start_time": "2021-02-15T09:18:43.000455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lr_finder_results(lr_finder): \n",
    "    # Create subplot grid\n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    # layout ={'title': 'Lr_finder_result'}\n",
    "    \n",
    "    # Create a line (trace) for the lr vs loss, gradient of loss\n",
    "    trace0 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['smooth_loss'],name='log_lr vs smooth_loss')\n",
    "    trace1 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['grad_loss'],name='log_lr vs loss gradient')\n",
    "\n",
    "    # Add subplot trace & assign to each grid\n",
    "    fig.add_trace(trace0, row=1, col=1);\n",
    "    fig.add_trace(trace1, row=1, col=2);\n",
    "    iplot(fig, show_link=False)\n",
    "    #fig.write_html(CFG.MODEL_NAME + '_lr_find.html');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "saved-fiber",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:43.133881Z",
     "iopub.status.busy": "2021-02-15T09:18:43.132873Z",
     "iopub.status.idle": "2021-02-15T09:18:43.136469Z",
     "shell.execute_reply": "2021-02-15T09:18:43.135878Z"
    },
    "papermill": {
     "duration": 0.059229,
     "end_time": "2021-02-15T09:18:43.136586",
     "exception": false,
     "start_time": "2021-02-15T09:18:43.077357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lr(model, optimizer, data_loader, init_value = 1e-8, final_value=100.0, beta = 0.98, num_batches = 200):\n",
    "    assert(num_batches > 0)\n",
    "    mult = (final_value / init_value) ** (1/num_batches)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    batch_num = 0\n",
    "    avg_loss = 0.0\n",
    "    best_loss = 0.0\n",
    "    smooth_losses = []\n",
    "    raw_losses = []\n",
    "    log_lrs = []\n",
    "    dataloader_it = iter(data_loader)\n",
    "    progress_bar = tqdm(range(num_batches))                \n",
    "        \n",
    "    for idx in progress_bar:\n",
    "        batch_num += 1\n",
    "        try:\n",
    "            inputs, targets = next(dataloader_it)\n",
    "            #print(images.shape)\n",
    "        except:\n",
    "            dataloader_it = iter(data_loader)\n",
    "            inputs, targets = next(dataloader_it)\n",
    "\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # handle exception in criterion\n",
    "        try:\n",
    "            # Forward pass\n",
    "            y_preds = model(inputs)\n",
    "            posLoss, floorLoss = criterion(y_preds, targets)\n",
    "            loss = posLoss + floorLoss\n",
    "        except:\n",
    "            if len(smooth_losses) > 1:\n",
    "                grad_loss = np.gradient(smooth_losses)\n",
    "            else:\n",
    "                grad_loss = 0.0\n",
    "            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n",
    "            return lr_finder_results \n",
    "                    \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        \n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 50 * best_loss:\n",
    "            if len(smooth_losses) > 1:\n",
    "                grad_loss = np.gradient(smooth_losses)\n",
    "            else:\n",
    "                grad_loss = 0.0\n",
    "            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n",
    "            return lr_finder_results\n",
    "        \n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        \n",
    "        #Store the values\n",
    "        raw_losses.append(loss.item())\n",
    "        smooth_losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print info\n",
    "        progress_bar.set_description(f\"loss:{loss.item()},smoothLoss: {smoothed_loss},lr:{lr}\")\n",
    "\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    \n",
    "    grad_loss = np.gradient(smooth_losses)\n",
    "    lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n",
    "                         'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n",
    "    return lr_finder_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "responsible-humanity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:43.214844Z",
     "iopub.status.busy": "2021-02-15T09:18:43.213286Z",
     "iopub.status.idle": "2021-02-15T09:18:43.217169Z",
     "shell.execute_reply": "2021-02-15T09:18:43.216590Z"
    },
    "papermill": {
     "duration": 0.048229,
     "end_time": "2021-02-15T09:18:43.217286",
     "exception": false,
     "start_time": "2021-02-15T09:18:43.169057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.LR_FIND == True:\n",
    "    # create dataset instance\n",
    "    tempX, tempY,_ = getBuildingData(buildingCsvPath=buildingsList[0])\n",
    "    tempX = stdScaler.fit_transform(tempX)\n",
    "    tempTrainDataset = wiFiFeaturesDataset(tempX, tempY)\n",
    "    tempTrainDataloader = DataLoader(tempTrainDataset, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n",
    "    \n",
    "    # create model instance   \n",
    "    model = wiFiFeaturesMLPModel(n_input=tempX.shape[1], n_output=3)\n",
    "    model.to(device);\n",
    "    \n",
    "    # optimizer function, lr schedulers and loss function\n",
    "    optimizer = getOptimizer(model)\n",
    "    criterion = competitionMetric\n",
    "    lrFinderResults = find_lr(model, optimizer, tempTrainDataloader)\n",
    "    plot_lr_finder_results(lrFinderResults)\n",
    "    del tempX, tempY, tempTrainDataset, tempTrainDataloader, model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-snowboard",
   "metadata": {},
   "source": [
    "## Train & Validate one section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intermediate-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainValidateOneFold(i_fold, model, optimizer, scheduler, dataloader_train, dataloader_valid):\n",
    "    trainFoldResults = []\n",
    "    bestValScore = np.inf\n",
    "    bestEpoch = 0\n",
    "\n",
    "    for epoch in range(CFG.N_EPOCHS):\n",
    "        #print('Epoch {}/{}'.format(epoch + 1, CFG.N_EPOCHS))\n",
    "        model.train()\n",
    "        trainPosLoss = 0.0\n",
    "        trainFloorLoss = 0.0\n",
    "\n",
    "        # training iterator\n",
    "        tr_iterator = iter(dataloader_train)\n",
    "\n",
    "        for idx in range(len(dataloader_train)):\n",
    "            try:\n",
    "                inputs, targets = next(tr_iterator)\n",
    "            except StopIteration:\n",
    "                tr_iterator = iter(dataloader_train)\n",
    "                inputs, targets = next(tr_iterator)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)  \n",
    "\n",
    "            # builtin package to handle automatic mixed precision\n",
    "            with autocast():\n",
    "                # Forward pass\n",
    "                y_preds = model(inputs)   \n",
    "                posLoss, floorLoss = criterion(y_preds, targets)\n",
    "                loss = posLoss # + floorLoss\n",
    "\n",
    "                # Backward pass\n",
    "                scaler.scale(loss).backward()        \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "\n",
    "                # log the necessary losses\n",
    "                trainPosLoss   += posLoss.item()\n",
    "                trainFloorLoss += floorLoss.item()\n",
    "\n",
    "                if scheduler is not None: \n",
    "                    if CFG.SCHEDULER == 'CosineAnnealingWarmRestarts':\n",
    "                        scheduler.step(epoch + idx / len(dataloader_train)) \n",
    "                    # onecyle lr scheduler / CosineAnnealingLR scheduler\n",
    "                    else:\n",
    "                        scheduler.step()\n",
    "                    \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        valTotalLoss = 0.0\n",
    "        valPosLoss = 0.0\n",
    "        valFloorLoss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        valid_iterator = iter(dataloader_valid)\n",
    "\n",
    "        for idx in range(len(dataloader_valid)):\n",
    "            try:\n",
    "                inputs, targets = next(valid_iterator)\n",
    "            except StopIteration:\n",
    "                valid_iterator = iter(dataloader_valid)\n",
    "                inputs, targets = next(valid_iterator)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)  \n",
    "\n",
    "            # forward prediction\n",
    "            with torch.no_grad():    \n",
    "                y_preds = model(inputs)\n",
    "\n",
    "            # store predictions and targets to compute metrics later\n",
    "            val_targets.append(targets)\n",
    "            val_preds.append(y_preds)\n",
    "\n",
    "        val_preds = torch.cat(val_preds, 0)\n",
    "        val_targets = torch.cat(val_targets, 0)\n",
    "        valPosLoss, valFloorLoss = competitionMetric(val_preds, val_targets)\n",
    "        valScore = valPosLoss #+ valFloorLoss\n",
    "        \n",
    "        # store results\n",
    "        trainFoldResults.append({ 'fold': i_fold, \n",
    "                                  'epoch': epoch, \n",
    "                                  'trainPosLoss': trainPosLoss / len(dataloader_train), \n",
    "                                  'trainFloorLoss': trainFloorLoss / len(dataloader_train), \n",
    "                                  'valPosLoss': valPosLoss.item() , 'valFloorLoss': valFloorLoss.item()})\n",
    "\n",
    "        # print to console\n",
    "        #if CFG.PRINT_N_EPOCH:\n",
    "            #print(f\"Fold :{i_fold},Epoch:{epoch},trainLoss={trainPosLoss/len(dataloader_train):.4f},{trainFloorLoss/len(dataloader_train) :.4f}, valLoss={valPosLoss.item():.4f},{valFloorLoss.item():.4f}\")\n",
    "        \n",
    "        # save best models        \n",
    "        if(valScore < bestValScore):\n",
    "            # reset variables\n",
    "            bestValScore = valScore\n",
    "            bestEpoch = epoch\n",
    "\n",
    "            # save model weights\n",
    "            torch.save({'model': model.state_dict(), 'val_preds':val_preds, 'val_targets':val_targets}, \n",
    "                        f\"{modelOutputDir}/{CFG.MODEL_NAME}_fold_{i_fold}_epoch{epoch}.pth\")\n",
    "\n",
    "    print(f\"For Fold {i_fold}, Best validation score of {bestValScore} was got at epoch {bestEpoch}\")                \n",
    "    return trainFoldResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-burton",
   "metadata": {},
   "source": [
    "## Training & Validation main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "planned-judges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9296, 10170) (9296, 3) (9296,)\n",
      "Fold 1/5\n",
      "For Fold 0, Best validation score of 9.048604965209961 was got at epoch 26\n",
      "Fold 2/5\n",
      "For Fold 1, Best validation score of 8.98095417022705 was got at epoch 5\n",
      "Fold 3/5\n",
      "For Fold 2, Best validation score of 8.602737426757812 was got at epoch 27\n",
      "Fold 4/5\n",
      "For Fold 3, Best validation score of 8.7635498046875 was got at epoch 28\n",
      "Fold 5/5\n",
      "For Fold 4, Best validation score of 10.40999698638916 was got at epoch 25\n",
      "CPU times: user 1h 19min 10s, sys: 21min 42s, total: 1h 40min 53s\n",
      "Wall time: 1h 42min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if CFG.TRAIN == True:\n",
    "    # placeholder to store results\n",
    "    trainResults = []\n",
    "\n",
    "    # for building in buildingList:\n",
    "    X, y, groups = getBuildingData(buildingCsvPath=buildingsList[0])\n",
    "    print(X.shape, y.shape, groups.shape)\n",
    "\n",
    "    for i_fold, (train_idx, valid_idx) in enumerate(folds.split(X=X, y=y[:,0],groups=groups)):\n",
    "        if i_fold in CFG.FOLD_TO_TRAIN:\n",
    "            print(\"Fold {}/{}\".format(i_fold + 1, CFG.N_FOLDS))\n",
    "            # print(train_idx.shape, valid_idx.shape)\n",
    "            \n",
    "            # splitting into train and validataion sets\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "                                        \n",
    "            # normalize input\n",
    "            #print(f\"Before stdscaler : train_mean{X_train.mean(), X_train.std(), X_valid.mean(), X_valid.std()}\")\n",
    "            X_train = stdScaler.fit_transform(X_train)\n",
    "            X_valid = stdScaler.transform(X_valid)\n",
    "            #print(f\"After stdscaler : train_mean{X_train.mean(), X_train.std(), X_valid.mean(), X_valid.std()}\")\n",
    "            #print(f\"x,y shapes = {X_train.shape, y_train.shape, X_valid.shape, y_valid.shape}\")\n",
    "            \n",
    "            # move to GPU if present\n",
    "            #X_train = torch.from_numpy(X_train.astype(np.float32)).to(device)\n",
    "            #y_train = torch.from_numpy(y_train.astype(np.float32)).to(device)\n",
    "            #X_valid = torch.from_numpy(X_valid.astype(np.float32)).to(device)\n",
    "            #y_valid = torch.from_numpy(y_valid.astype(np.float32)).to(device)\n",
    "            \n",
    "            # create torch Datasets and Dataloader for each fold's train and validation data\n",
    "            dataset_train = wiFiFeaturesDataset(X_train, y_train)\n",
    "            dataset_valid = wiFiFeaturesDataset(X_valid, y_valid)            \n",
    "            dataloader_train = DataLoader(dataset_train, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                                      num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n",
    "            dataloader_valid = DataLoader(dataset_valid, batch_size= CFG.TEST_BATCH_SIZE, shuffle=True,\n",
    "                                      num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n",
    "            \n",
    "            # supervised model instance and move to compute device\n",
    "            model = wiFiFeaturesMLPModel(n_input=X_train.shape[1], n_output=3)\n",
    "            model.to(device);\n",
    "            # print(f\"there are {find_no_of_trainable_params(model)} params in model\")\n",
    "            \n",
    "            # optimizer function, lr schedulers and loss function\n",
    "            optimizer = getOptimizer(model)\n",
    "            scheduler = getScheduler(optimizer, dataloader_train)\n",
    "            criterion = competitionMetric\n",
    "            # print(f\"optimizer={optimizer}, scheduler={scheduler}, loss_fn={criterion}\")\n",
    "\n",
    "            # train and validate single fold\n",
    "            foldResults = trainValidateOneFold(i_fold, model, optimizer, scheduler,\\\n",
    "                                               dataloader_train, dataloader_valid)\n",
    "            trainResults = trainResults + foldResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imposed-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>trainPosLoss</th>\n",
       "      <th>trainFloorLoss</th>\n",
       "      <th>valPosLoss</th>\n",
       "      <th>valFloorLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.952648</td>\n",
       "      <td>21.110264</td>\n",
       "      <td>12.569757</td>\n",
       "      <td>22.786444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.899113</td>\n",
       "      <td>21.098015</td>\n",
       "      <td>14.258412</td>\n",
       "      <td>22.786444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23.148408</td>\n",
       "      <td>21.095223</td>\n",
       "      <td>11.834853</td>\n",
       "      <td>22.786444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  epoch  trainPosLoss  trainFloorLoss  valPosLoss  valFloorLoss\n",
       "0     0      0     49.952648       21.110264   12.569757     22.786444\n",
       "1     0      1     23.899113       21.098015   14.258412     22.786444\n",
       "2     0      2     23.148408       21.095223   11.834853     22.786444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainResults = pd.DataFrame(trainResults)\n",
    "trainResults['valTotalLoss'] = trainResults['valPosLoss'] + trainResults['valFloorLoss']\n",
    "trainResults['trainTotalLoss'] = trainResults['trainPosLoss'] + trainResults['trainFloorLoss']\n",
    "trainResults.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrainingResults(trainResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "first-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>trainPosLoss</th>\n",
       "      <th>trainFloorLoss</th>\n",
       "      <th>valPosLoss</th>\n",
       "      <th>valFloorLoss</th>\n",
       "      <th>valTotalLoss</th>\n",
       "      <th>trainTotalLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.343768</td>\n",
       "      <td>21.096619</td>\n",
       "      <td>9.048605</td>\n",
       "      <td>22.786444</td>\n",
       "      <td>31.835049</td>\n",
       "      <td>42.440387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.121548</td>\n",
       "      <td>22.075527</td>\n",
       "      <td>8.980954</td>\n",
       "      <td>18.889187</td>\n",
       "      <td>27.870141</td>\n",
       "      <td>44.197075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.229462</td>\n",
       "      <td>21.943548</td>\n",
       "      <td>8.602737</td>\n",
       "      <td>19.427420</td>\n",
       "      <td>28.030157</td>\n",
       "      <td>43.173010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.618944</td>\n",
       "      <td>21.689361</td>\n",
       "      <td>8.763550</td>\n",
       "      <td>20.414200</td>\n",
       "      <td>29.177750</td>\n",
       "      <td>43.308305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.966408</td>\n",
       "      <td>20.377481</td>\n",
       "      <td>10.409997</td>\n",
       "      <td>25.658955</td>\n",
       "      <td>36.068952</td>\n",
       "      <td>41.343890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fold  epoch  trainPosLoss  trainFloorLoss  valPosLoss  valFloorLoss  \\\n",
       "26    0.0   26.0     21.343768       21.096619    9.048605     22.786444   \n",
       "55    1.0    5.0     22.121548       22.075527    8.980954     18.889187   \n",
       "127   2.0   27.0     21.229462       21.943548    8.602737     19.427420   \n",
       "178   3.0   28.0     21.618944       21.689361    8.763550     20.414200   \n",
       "225   4.0   25.0     20.966408       20.377481   10.409997     25.658955   \n",
       "\n",
       "     valTotalLoss  trainTotalLoss  \n",
       "26      31.835049       42.440387  \n",
       "55      27.870141       44.197075  \n",
       "127     28.030157       43.173010  \n",
       "178     29.177750       43.308305  \n",
       "225     36.068952       41.343890  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestResults = []\n",
    "for fold in range(CFG.N_FOLDS):\n",
    "    foldDf = trainResults[trainResults['fold']== fold]\n",
    "    bestResults.append(foldDf.iloc[np.argmin(foldDf['valTotalLoss'].values),:])\n",
    "bestResults =pd.DataFrame(bestResults)\n",
    "bestResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interested-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "trainResults.to_csv(f\"{modelOutputDir}/{getBuildingName(buildingsList[0])}_{CFG.MODEL_NAME}_trainResults.csv\")\n",
    "bestResults.to_csv(f\"{modelOutputDir}/{getBuildingName(buildingsList[0])}_{CFG.MODEL_NAME}_bestResults.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
