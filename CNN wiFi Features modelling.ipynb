{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-species",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liable-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# metrics calculation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# basic plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# interactive plots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-solution",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "green-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # pipeline parameters\n",
    "    SEED        = 42\n",
    "    TRAIN       = True\n",
    "    LR_FIND     = False\n",
    "    TEST        = False\n",
    "    N_FOLDS     = 5 \n",
    "    N_EPOCHS    = 27 \n",
    "    TEST_BATCH_SIZE  = 32\n",
    "    TRAIN_BATCH_SIZE = 16\n",
    "    NUM_WORKERS      = 4\n",
    "    DATA_FRAC        = 1.0\n",
    "    FOLD_TO_TRAIN    = [0] # , 1, 2, 3, 4\n",
    "\n",
    "    # model parameters\n",
    "    MODEL_ARCH  = 'tf_efficientnet_b4_ns'\n",
    "    MODEL_NAME  = 'eff_b4_v5'\n",
    "    WGT_PATH    = ''\n",
    "    WGT_MODEL   = ''\n",
    "    \n",
    "    # scheduler variables\n",
    "    MAX_LR    = 1e-3\n",
    "    MIN_LR    = 1e-6\n",
    "    SCHEDULER = 'CosineAnnealingLR'  # ['ReduceLROnPlateau', 'OneCycleLR', CosineAnnealingWarmRestarts']\n",
    "    T_0       = 10   # CosineAnnealingWarmRestarts\n",
    "    T_MAX     = 2.5    # CosineAnnealingLR\n",
    "\n",
    "    # optimizer variables\n",
    "    OPTIMIZER     = 'Adam'\n",
    "    WEIGHT_DECAY  = 1e-6\n",
    "    GRD_ACC_STEPS = 1\n",
    "    MAX_GRD_NORM  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "timely-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5a0546857ecc773753327266_train.csv']\n"
     ]
    }
   ],
   "source": [
    "floor_map = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\n",
    "             \"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n",
    "\n",
    "minCount = 1\n",
    "rssiFillerValue = -999.0\n",
    "dtFillerValue   = 1000.0\n",
    "freqFillerValue = 0\n",
    "outputDir = 'referencePublicNotebooks/wiFiFeatures'\n",
    "sampleCsvPath = 'sample_submission.csv'\n",
    "\n",
    "\n",
    "buildingsList = glob.glob(f\"{outputDir}/*.csv\")\n",
    "print([x.split('/')[-1] for x in buildingsList])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-market",
   "metadata": {
    "papermill": {
     "duration": 0.030885,
     "end_time": "2021-02-15T09:18:40.779692",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.748807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loved-theme",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:40.849777Z",
     "iopub.status.busy": "2021-02-15T09:18:40.847758Z",
     "iopub.status.idle": "2021-02-15T09:18:40.850551Z",
     "shell.execute_reply": "2021-02-15T09:18:40.851077Z"
    },
    "papermill": {
     "duration": 0.040621,
     "end_time": "2021-02-15T09:18:40.851226",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.810605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjustable-shower",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T09:18:40.921617Z",
     "iopub.status.busy": "2021-02-15T09:18:40.920714Z",
     "iopub.status.idle": "2021-02-15T09:18:40.927627Z",
     "shell.execute_reply": "2021-02-15T09:18:40.926924Z"
    },
    "papermill": {
     "duration": 0.045466,
     "end_time": "2021-02-15T09:18:40.927741",
     "exception": false,
     "start_time": "2021-02-15T09:18:40.882275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-patrick",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "special-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiFiFeaturesDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data, transform=None):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.from_numpy(self.X_data[index].astype(np.float32))\n",
    "        y = torch.from_numpy(self.y_data[index].astype(np.float32))\n",
    "        return x,y\n",
    "    \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-marriage",
   "metadata": {},
   "source": [
    "## MLP Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spanish-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wiFiFeaturesMLPModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(in_features=n_input, out_features=512)\n",
    "        self.lin2 = nn.Linear(in_features=512,     out_features=32)\n",
    "        self.lin3 = nn.Linear(in_features=32,      out_features= 3)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.drops = nn.Dropout(0.3)        \n",
    "\n",
    "    def forward(self, x_input):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-crystal",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "static-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = buildingsList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "french-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9296, 10174)\n",
      "(9296, 10170) (9296, 3) (9296,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read building data \n",
    "data = pd.read_csv(building)\n",
    "# use fraction if needed\n",
    "if CFG.DATA_FRAC < 1:\n",
    "    data = data.sample(frac=CFG.DATA_FRAC).reset_index(drop=True)\n",
    "#data.head(3)\n",
    "print(data.shape)\n",
    "\n",
    "# separate into features and target variables\n",
    "X = data.iloc[:,0:-4].values\n",
    "y = data.iloc[:,-4:-1].values\n",
    "groups = data.iloc[:,-1].values\n",
    "print(X.shape, y.shape, groups.shape)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "classical-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7437,) (1859,)\n"
     ]
    }
   ],
   "source": [
    "folds = GroupKFold(n_splits=CFG.N_FOLDS)\n",
    "for i_fold, (train_idx, valid_idx) in enumerate(folds.split(X=X, y=y[:,0],groups=groups)):\n",
    "    break\n",
    "print(train_idx.shape, valid_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupational-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and validataion sets\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_valid, y_valid = X[valid_idx], y[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nominated-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stdscaler : train_mean(137.06707880060725, 1136.4634492114315, 127.1956956176943, 1116.6455077288429)\n",
      "After stdscaler : train_mean(-1.4644823927370838e-17, 0.9930436512134494, 0.08787075280251733, 19.70137847102953)\n"
     ]
    }
   ],
   "source": [
    "# normalize input\n",
    "print(f\"Before stdscaler : train_mean{X_train.mean(), X_train.std(), X_valid.mean(), X_valid.std()}\")\n",
    "stdScaler = StandardScaler()\n",
    "X_train = stdScaler.fit_transform(X_train)\n",
    "X_valid = stdScaler.transform(X_valid)\n",
    "print(f\"After stdscaler : train_mean{X_train.mean(), X_train.std(), X_valid.mean(), X_valid.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "warming-retro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7437, 10170), (7437, 3), (1859, 10170), (1859, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intelligent-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = wiFiFeaturesDataset(X_train, y_train)\n",
    "dataset_valid = wiFiFeaturesDataset(X_valid, y_valid)            \n",
    "dataloader_train = DataLoader(dataset_train, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size= CFG.TEST_BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the metric used in this competition\n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = torch.sqrt(torch.square(torch.subtract(xhat,x)) + \n",
    "                              torch.square(torch.subtract(yhat,y)) +\n",
    "                              15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
