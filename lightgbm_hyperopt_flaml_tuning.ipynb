{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Most of this notebook is inspired from the wonderful gitrepos\n",
    "\n",
    "1. [ml course ai hyperopt](https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_english/tutorials/hyperparameters_tunning_ilya_larchenko.ipynb)\n",
    "\n",
    "2. [Flaml github](https://github.com/microsoft/FLAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "\n",
    "# models libraries\n",
    "#from lightgbm.sklearn import LGBMRegressor\n",
    "from lightgbm import LGBMRegressor,LGBMClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# sklearn imports \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# hyperopt imports to perform bayesian optimisation \n",
    "from hyperopt import Trials, anneal, fmin, hp, tpe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the metric used in this competition\n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt(np.power(xhat - x,2) + np.power(yhat-y,2)) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum()/xhat.shape[0]\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    #torch.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed(seed)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "\n",
    "# cv strategy \n",
    "N_FOLDS = 5\n",
    "folds = GroupKFold(n_splits=N_FOLDS)\n",
    "\n",
    "# which optimisation to perform\n",
    "perform_RandomCVSearch = False\n",
    "perform_hyperoptParsenEstimator = False\n",
    "perform_hyperoptSimpleAnnealing = False\n",
    "perfom_flaml = True\n",
    "\n",
    "\n",
    "# number of experiments to perform for hyperopt\n",
    "n_iter = 100\n",
    "\n",
    "# target time for flaml, in seconds\n",
    "timeLimit = 30  #~8 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24\n"
     ]
    }
   ],
   "source": [
    "feature_dir = \"referencePublicNotebooks/1000Features/\"\n",
    "\n",
    "# get our train and test files\n",
    "train_files = sorted(glob.glob(os.path.join(feature_dir, 'train/*_train.csv')))\n",
    "test_files = sorted(glob.glob(os.path.join(feature_dir, 'test/*_test.csv')))\n",
    "ssubm = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "print(len(train_files),len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9296, 945)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000840e5c600de293cea57f13326f273c86c3988</th>\n",
       "      <th>00ad587dcb9c7ce3788b92e22777a22ee0efea31</th>\n",
       "      <th>00af060fc145ee6a6a50475efa57b91cbf54237f</th>\n",
       "      <th>00bcc61bdea4d52d050822d66952dd707c2fcdf3</th>\n",
       "      <th>00f0904087c01d922d6ebf3005607dfdeaf6687b</th>\n",
       "      <th>011e20ebf721a1c6dfec42e8ed1e2ac566073a2a</th>\n",
       "      <th>01d2f676abab6ec03ec5dc696bfd49d66e392ea1</th>\n",
       "      <th>01e25e4a25acd32baf5137b3031151f751fadbb4</th>\n",
       "      <th>026c2f057932da75680b21ecdbd23bf9cb9350f3</th>\n",
       "      <th>028a310e23177c3747d37971678dd964ee28ce17</th>\n",
       "      <th>...</th>\n",
       "      <th>fdc189e5a19850397f37201f4acc378cfddcf0d6</th>\n",
       "      <th>fdc19f011587b75c11a6c30d8ca06d90107b6bde</th>\n",
       "      <th>fdf37fa13679f581bdfaae3b99e368633e0a144b</th>\n",
       "      <th>fdfe926caf5f49a88a9bcab8d025e887f422128b</th>\n",
       "      <th>fe3211f90e4ab1f500e10fe175ae6142f4b13130</th>\n",
       "      <th>ffa41c79865d7fb336f586e0dec8b080db1027fb</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>155.65668</td>\n",
       "      <td>89.40598</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e158edff4c3420006d52172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>155.65668</td>\n",
       "      <td>89.40598</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e158edff4c3420006d52172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>154.68399</td>\n",
       "      <td>81.80792</td>\n",
       "      <td>-1</td>\n",
       "      <td>5e158edff4c3420006d52172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 945 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000840e5c600de293cea57f13326f273c86c3988  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   00ad587dcb9c7ce3788b92e22777a22ee0efea31  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   00af060fc145ee6a6a50475efa57b91cbf54237f  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   00bcc61bdea4d52d050822d66952dd707c2fcdf3  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   00f0904087c01d922d6ebf3005607dfdeaf6687b  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   011e20ebf721a1c6dfec42e8ed1e2ac566073a2a  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   01d2f676abab6ec03ec5dc696bfd49d66e392ea1  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   01e25e4a25acd32baf5137b3031151f751fadbb4  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   026c2f057932da75680b21ecdbd23bf9cb9350f3  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   028a310e23177c3747d37971678dd964ee28ce17  ...  \\\n",
       "4                                      -999  ...   \n",
       "4                                      -999  ...   \n",
       "4                                      -999  ...   \n",
       "\n",
       "   fdc189e5a19850397f37201f4acc378cfddcf0d6  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   fdc19f011587b75c11a6c30d8ca06d90107b6bde  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   fdf37fa13679f581bdfaae3b99e368633e0a144b  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   fdfe926caf5f49a88a9bcab8d025e887f422128b  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   fe3211f90e4ab1f500e10fe175ae6142f4b13130  \\\n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "4                                      -999   \n",
       "\n",
       "   ffa41c79865d7fb336f586e0dec8b080db1027fb          x         y  f  \\\n",
       "4                                      -999  155.65668  89.40598 -1   \n",
       "4                                      -999  155.65668  89.40598 -1   \n",
       "4                                      -999  154.68399  81.80792 -1   \n",
       "\n",
       "                       path  \n",
       "4  5e158edff4c3420006d52172  \n",
       "4  5e158edff4c3420006d52172  \n",
       "4  5e158edff4c3420006d52172  \n",
       "\n",
       "[3 rows x 945 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a particular site and choosing y coorindate\n",
    "e = 0\n",
    "data = pd.read_csv(train_files[e], index_col=0)\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data.iloc[:,:-4].values.astype(int)\n",
    "y_trainy = data.iloc[:,-3].values.astype(float)\n",
    "y_trainx = data.iloc[:,-4].values.astype(float)\n",
    "y_trainf = data.iloc[:,-2].values.astype(float)\n",
    "groups = data[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normlise inputs\n",
    "stdScaler = StandardScaler()\n",
    "x_train = stdScaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Lightgbm and SVR model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score for y coordinate is 77.47947111520742\n",
      "[90.20551365 92.8808168  53.35521555 68.3332076  82.62260198]\n",
      "CPU times: user 55.1 ms, sys: 64.4 ms, total: 119 ms\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline lightgbm model\n",
    "model = LGBMRegressor(n_estimators=125, num_leaves=90, random_state=SEED)\n",
    "results = -cross_val_score(model, X=x_train, y=y_trainy, groups=groups, \n",
    "                              scoring=\"neg_mean_squared_error\", cv=folds, n_jobs=-1)\n",
    "print(f\"Cross val score for y coordinate is {results.mean()}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# baseline svm model\n",
    "# svrModel = SVR(C=100.0, epsilon=0.01)\n",
    "# results = -cross_val_score(svrModel, X=x_train, y=y_trainy, groups=groups, \n",
    "#                              scoring=\"neg_mean_squared_error\", cv=folds, n_jobs=-1)\n",
    "# print(f\"Cross val score for y coordinate is {results.mean()}\")\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if perform_RandomCVSearch == True:\n",
    "\n",
    "    param_grid_rand = {\n",
    "    \"learning_rate\": np.logspace(-5, 0, 100),\n",
    "    \"max_depth\": randint(2, 20),\n",
    "    \"n_estimators\": randint(100, 2000),\n",
    "    \"random_state\": [SEED],\n",
    "    }\n",
    "    \n",
    "    rs = RandomizedSearchCV(model,\n",
    "        param_grid_rand,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        #fit_params=None,\n",
    "        n_jobs=-1,\n",
    "        cv=folds,\n",
    "        verbose=True,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    rs.fit(x_train, y_trainy, groups=groups)\n",
    "    print(\"Best MSE {:.3f} params {}\".format(-rs.best_score_, rs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_RandomCVSearch == True:\n",
    "    rs_results_df = pd.DataFrame(\n",
    "        np.transpose(\n",
    "            [\n",
    "                -rs.cv_results_[\"mean_test_score\"],\n",
    "                rs.cv_results_[\"param_learning_rate\"].data,\n",
    "                rs.cv_results_[\"param_max_depth\"].data,\n",
    "                rs.cv_results_[\"param_n_estimators\"].data,\n",
    "            ]\n",
    "        ),\n",
    "        columns=[\"score\", \"learning_rate\", \"max_depth\", \"n_estimators\"],\n",
    "    )\n",
    "    rs_results_df.plot(subplots=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt tuning methods\n",
    "### Tree-structured Parzen Estimator and Simple Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_mse_cv(params, X=x_train, y=y_trainy, cv=folds,random_state=SEED):\n",
    "    # the function gest a set of variable parameters in \"param\"\n",
    "    lgb_params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"l2\",\n",
    "        \"verbosity\": -1,\n",
    "        \n",
    "        # fixed params\n",
    "        \"boosting_type\": \"gbdt\", \n",
    "        \"subsample_freq\":20,\n",
    "        \"max_depth\":6,\n",
    "\n",
    "        # variable parameters\n",
    "        \"num_leaves\": int(params[\"num_leaves\"]),\n",
    "        \"feature_fraction\": float(params[\"feature_fraction\"]),\n",
    "        \"bagging_fraction\": float(params[\"bagging_fraction\"]),        \n",
    "        \"learning_rate\": float(params[\"learning_rate\"]),\n",
    "        \"n_estimators\": int(params[\"n_estimators\"]),\n",
    "        \"lambda_l1\": float(params[\"lambda_l1\"]),\n",
    "        \"lambda_l2\": float(params[\"lambda_l2\"]),\n",
    "        \"min_child_samples\": int(params[\"min_child_samples\"]),\n",
    "    }\n",
    "    \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = LGBMRegressor(random_state=SEED, **lgb_params)\n",
    "\n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X=X, y=y, groups=groups, scoring=\"neg_mean_squared_error\",\n",
    "                             cv=folds, n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible values of parameters\n",
    "space = {\n",
    "        # variable parameters\n",
    "        \"num_leaves\": hp.quniform(\"num_leaves\", 10, 100, 1),\n",
    "        \"feature_fraction\": hp.choice('feature_fraction', np.linspace(0.4, 0.7, 3,dtype=float)),\n",
    "        \"bagging_fraction\": hp.choice('bagging_fraction', np.linspace(0.4, 0.7, 3,dtype=float)),        \n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -2, -1), \n",
    "        \"n_estimators\": hp.quniform(\"n_estimators\", 500, 10000, 1),\n",
    "        \"lambda_l1\": hp.loguniform(\"lambda_l1\", -6, 1.0), \n",
    "        \"lambda_l2\": hp.loguniform(\"lambda_l2\", -6, 1.0), \n",
    "        \"min_child_samples\": hp.quniform(\"min_child_samples\", 5, 100, 1)\n",
    "        }\n",
    "\n",
    "# trials will contain logging information\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuningAlgorithm = None\n",
    "\n",
    "# choice of tuning algorithm\n",
    "if perform_hyperoptParsenEstimator == True:\n",
    "    tuningAlgorithm = tpe.suggest\n",
    "if perform_hyperoptSimpleAnnealing == True:\n",
    "    tuningAlgorithm = anneal.suggest\n",
    "if perfom_flaml == True:\n",
    "    tuningAlgorithm = 'flaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaml\n"
     ]
    }
   ],
   "source": [
    "print(tuningAlgorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if((perform_hyperoptParsenEstimator == True) or (perform_hyperoptSimpleAnnealing == True)):\n",
    "    best = fmin(\n",
    "        fn=gb_mse_cv,                       # function to optimize\n",
    "        space=space,                        # search space\n",
    "        algo=tuningAlgorithm,               # optimization algorithm, hyperotp will select its parameters automatically\n",
    "        max_evals=n_iter,                   # maximum number of iterations\n",
    "        trials=trials,                      # logging\n",
    "        show_progressbar=True,\n",
    "        rstate=np.random.RandomState(SEED), # fixing random state for the reproducibility\n",
    "    )\n",
    "    print(\"Best MSE {:.3f} params {}\".format(gb_mse_cv(best), best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot optimizer results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if((perform_hyperoptParsenEstimator == True) or (perform_hyperoptSimpleAnnealing == True)):\n",
    "    optimizer_results = np.array([[\n",
    "                x[\"result\"][\"loss\"],  \n",
    "                x[\"misc\"][\"vals\"][\"n_estimators\"][0],    \n",
    "                x[\"misc\"][\"vals\"][\"learning_rate\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"num_leaves\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"feature_fraction\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"bagging_fraction\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"lambda_l1\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"lambda_l2\"][0],\n",
    "                x[\"misc\"][\"vals\"][\"min_child_samples\"][0],        \n",
    "            ] for x in trials.trials ])\n",
    "\n",
    "    # create a df to plot\n",
    "    results_columns = [\"score\", \"n_estimators\", \"learning_rate\", \"num_leaves\", \"feature_fraction\",\n",
    "                       \"bagging_fraction\", \"lambda_l1\", \"lambda_l2\", \"min_child_samples\"]\n",
    "    optimizer_results_df = pd.DataFrame(optimizer_results, columns=results_columns)\n",
    "    optimizer_results_df.plot(subplots=True, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:28:35] {884} INFO - Evaluation method: cv\n",
      "[flaml.automl: 04-02 12:28:35] {601} INFO - Using RepeatedKFold\n",
      "[flaml.automl: 04-02 12:28:35] {905} INFO - Minimizing error metric: mse\n",
      "[flaml.automl: 04-02 12:28:35] {924} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost']\n",
      "[flaml.automl: 04-02 12:28:35] {986} INFO - iteration 0  current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:28:41] {1134} INFO -  at 6.2s,\tbest lgbm's error=822.7656,\tbest lgbm's error=822.7656\n",
      "[flaml.automl: 04-02 12:28:41] {986} INFO - iteration 1  current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:28:45] {1134} INFO -  at 10.3s,\tbest lgbm's error=822.7656,\tbest lgbm's error=822.7656\n",
      "[flaml.automl: 04-02 12:28:45] {986} INFO - iteration 2  current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:28:51] {1134} INFO -  at 16.3s,\tbest lgbm's error=56.2444,\tbest lgbm's error=56.2444\n",
      "[flaml.automl: 04-02 12:28:51] {986} INFO - iteration 3  current learner xgboost\n",
      "[flaml.automl: 04-02 12:28:53] {1134} INFO -  at 18.0s,\tbest xgboost's error=4887.5851,\tbest lgbm's error=56.2444\n",
      "[flaml.automl: 04-02 12:28:53] {986} INFO - iteration 4  current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:28:57] {1134} INFO -  at 22.1s,\tbest lgbm's error=56.2444,\tbest lgbm's error=56.2444\n",
      "[flaml.automl: 04-02 12:28:57] {986} INFO - iteration 5  current learner xgboost\n",
      "[flaml.automl: 04-02 12:28:58] {1134} INFO -  at 23.7s,\tbest xgboost's error=4887.5851,\tbest lgbm's error=56.2444\n",
      "[flaml.automl: 04-02 12:28:58] {986} INFO - iteration 6  current learner lgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=48, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=48\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 04-02 12:29:05] {1134} INFO -  at 30.3s,\tbest lgbm's error=51.0423,\tbest lgbm's error=51.0423\n",
      "[flaml.automl: 04-02 12:29:05] {1181} INFO - selected model: LGBMRegressor(colsample_bytree=0.9534346594834143, learning_rate=1.0,\n",
      "              max_bin=1023, max_leaves=4, min_data_in_leaf=48, n_estimators=4,\n",
      "              objective='regression', reg_alpha=0.0022085340760961856,\n",
      "              reg_lambda=0.5460627024738886, subsample=0.9814787163243814)\n",
      "[flaml.automl: 04-02 12:29:05] {939} INFO - fit succeeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparmeter config: {'n_estimators': 18.0, 'max_leaves': 4.0, 'min_data_in_leaf': 48.0, 'learning_rate': 1.0, 'subsample': 0.9814787163243814, 'log_max_bin': 10.0, 'colsample_bytree': 0.9534346594834143, 'reg_alpha': 0.0022085340760961856, 'reg_lambda': 0.5460627024738886}\n",
      "Best mse on validation data: 51.04\n",
      "Training duration of best run: 6.541 s\n",
      "LGBMRegressor(colsample_bytree=0.9534346594834143, learning_rate=1.0,\n",
      "              max_bin=1023, max_leaves=4, min_data_in_leaf=48, n_estimators=4,\n",
      "              objective='regression', reg_alpha=0.0022085340760961856,\n",
      "              reg_lambda=0.5460627024738886, subsample=0.9814787163243814)\n"
     ]
    }
   ],
   "source": [
    "if perfom_flaml == True:\n",
    "    settings = {\n",
    "        \"metric\": 'mse', # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "        \"task\": 'regression', # task type        \n",
    "        \"log_file_name\": 'lightgbm_ycoorindate.log', # flaml log file    \n",
    "        \"estimator_list\": ['lgbm', 'xgboost'], # list of ML learners; we tune lightgbm in this example\n",
    "        \"time_budget\": timeLimit, # total running time in seconds\n",
    "        \"eval_method\": 'cv',\n",
    "        \"n_splits\" : N_FOLDS, \n",
    "    }\n",
    "\n",
    "    # fit algorithms\n",
    "    automl.fit(X_train = x_train, y_train = y_trainy, **settings)\n",
    "\n",
    "    print('Best hyperparmeter config:', automl.best_config)\n",
    "    print('Best mse on validation data: {0:.4g}'.format(automl.best_loss))\n",
    "    print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "    \n",
    "    print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
