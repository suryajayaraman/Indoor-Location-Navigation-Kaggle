{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle5 as pickle\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "## for spline interpolation and evaluation\n",
    "from scipy.interpolate import splev, splrep\n",
    "\n",
    "## for ESEKF imports\n",
    "import sys\n",
    "sys.path.append('ESEKF/')\n",
    "from rotations import Quaternion, skew_symmetric\n",
    "\n",
    "## plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dask\n",
    "import multiprocessing\n",
    "from dask.distributed import wait\n",
    "from dask.distributed import Client, wait, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n_workers to number of cores\n",
    "## client = Client(n_workers=multiprocessing.cpu_count(), threads_per_worker=1)\n",
    "## client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_map = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\n",
    "             \"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n",
    "\n",
    "sampleCsvPath = 'sample_submission.csv'\n",
    "waypointData_trainPath = 'wayPointData_train.pickle'\n",
    "ssubm = pd.read_csv(sampleCsvPath)\n",
    "ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "\n",
    "outputDir = '.'\n",
    "featuresInputPath = 'referencePublicNotebooks/imuFeatures'\n",
    "pictureSaveDir = 'referencePublicNotebooks/splineFitOutput'\n",
    "ACC_COLS  = ['ts', 'ax', 'ay', 'az', 'a_acc']\n",
    "GYRO_COLS = ['ts', 'gx', 'gy', 'gz', 'g_acc']\n",
    "AHRS_COLS = ['ts', 'qx', 'qy', 'qz', 'q_acc']\n",
    "\n",
    "## exp weighted moving avg parameter\n",
    "smoothSpan = 10\n",
    "\n",
    "## gravity vector to calculte linear accelearation\n",
    "gravity = np.array([0.0, 0.0, -9.8])\n",
    "\n",
    "## number of time sequences to give as input to encoder\n",
    "imuInputSequenceLength = 100\n",
    "\n",
    "## max number of time sequences in decoder\n",
    "wayPointMaxSequenceLength = 107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dir() -> Path:\n",
    "    return Path('.')\n",
    "    #return Path('.')\n",
    "\n",
    "def generate_target_buildings() -> List[str]:\n",
    "    ssubm = pd.read_csv(sampleCsvPath)\n",
    "    ssubm_df = ssubm[\"site_path_timestamp\"].apply(\n",
    "        lambda x: pd.Series(x.split(\"_\")))\n",
    "    buildingsList = sorted(ssubm_df[0].value_counts().index.tolist()) # type: ignore\n",
    "    return buildingsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuildingPathFiles_test(building):\n",
    "    pathFilesTest = list(set(sorted(ssubm_df[ssubm_df[0] == building][1].values.tolist())))\n",
    "    buildingPathFilesTest = [f\"{input_dir()}/test/{path}.txt\" for path in pathFilesTest]\n",
    "    return buildingPathFilesTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWayPointData_train():\n",
    "    with open(waypointData_trainPath,'rb') as inputFile:\n",
    "        waypointData_train = pickle.load(inputFile)\n",
    "    return waypointData_train\n",
    "\n",
    "def getWayPointCount():\n",
    "    wayPointData_train = getWayPointData_train()\n",
    "    buildingList = sorted(wayPointData_train.building.unique().tolist())\n",
    "    pathList     = sorted(wayPointData_train.path.unique().tolist())\n",
    "\n",
    "    output = []\n",
    "    wayPointBins = [0,5,10,20,84,110]\n",
    "    for building, buildingData in wayPointData_train.groupby(by='building'):\n",
    "        for path, pathData in buildingData.groupby(by='path'):\n",
    "            output.append([building, path, pathData.shape[0]])\n",
    "\n",
    "    output = pd.DataFrame(output, columns =['building', 'path', 'count'])  \n",
    "    output['countBin'] = pd.cut(output['count'], bins=wayPointBins)\n",
    "    output.to_pickle('wayPoint_count.pickle')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_IMUData(pathFile):\n",
    "    acce, gyro, ahrs = [], [], []\n",
    "    with open(pathFile) as f:\n",
    "        for line_data in csv.reader(f, delimiter=\"\\t\", doublequote=True):\n",
    "            if line_data[1] == 'TYPE_ACCELEROMETER':\n",
    "                if len(line_data) > 5:\n",
    "                    accuracy = np.int16(line_data[-1])\n",
    "                else:\n",
    "                    accuracy = np.int16(3)\n",
    "                acce.append([np.int64(line_data[0]), np.float32(line_data[2]), np.float32(line_data[3]), np.float32(line_data[4]), accuracy])\n",
    "                continue\n",
    "\n",
    "            elif line_data[1] == 'TYPE_GYROSCOPE':\n",
    "                if len(line_data) > 5:\n",
    "                    accuracy = np.int16(line_data[-1])\n",
    "                else:\n",
    "                    accuracy = np.int16(3)               \n",
    "                gyro.append([np.int64(line_data[0]), np.float32(line_data[2]), np.float32(line_data[3]), np.float32(line_data[4]), accuracy])\n",
    "                continue\n",
    "\n",
    "            if line_data[1] == 'TYPE_ROTATION_VECTOR':\n",
    "                if len(line_data)>5:\n",
    "                    accuracy = np.int16(line_data[-1])\n",
    "                else:\n",
    "                    accuracy = np.int16(3)\n",
    "                if len(line_data)>=5:        \n",
    "                    ahrs.append([np.int64(line_data[0]), np.float32(line_data[2]), np.float32(line_data[3]), np.float32(line_data[4]), accuracy])\n",
    "                continue\n",
    "\n",
    "    ## sort data by timestamps\n",
    "    acce = sorted(acce, key=lambda x: x[0])\n",
    "    gyro = sorted(gyro, key=lambda x: x[0])\n",
    "    ahrs = sorted(ahrs, key=lambda x: x[0])\n",
    "    \n",
    "    acce = pd.DataFrame(acce, columns = ACC_COLS)\n",
    "    gyro = pd.DataFrame(gyro, columns = GYRO_COLS)\n",
    "    ahrs = pd.DataFrame(ahrs, columns = AHRS_COLS)\n",
    "    return acce, gyro, ahrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qw(qx,qy,qz):\n",
    "    qw = 0.0\n",
    "    temp = 1 - (qx**2 + qy**2 + qz**2)\n",
    "    if temp > 0.0:\n",
    "        qw = np.sqrt(temp)\n",
    "    return qw\n",
    "    \n",
    "\n",
    "def convertQuat(ahrsData):\n",
    "    numRows = ahrsData.shape[0]\n",
    "    rotMatList= []\n",
    "    rollList, pitchList, yawList = [], [], []    \n",
    "    for row in range(numRows):\n",
    "        quat = Quaternion(w=ahrsData['qw'][row], x=ahrsData['qx'][row],\\\n",
    "                          y=ahrsData['qy'][row], z=ahrsData['qz'][row])\n",
    "        eulerAngles = np.float64(quat.to_euler())\n",
    "        \n",
    "        ## add to output\n",
    "        rotMatList.append(np.float64(quat.to_mat()))\n",
    "        rollList.append(eulerAngles[0])\n",
    "        pitchList.append(eulerAngles[1])\n",
    "        yawList.append(eulerAngles[2])\n",
    "    return rotMatList, rollList, pitchList, yawList\n",
    "\n",
    "def processAHRSData(ahrs):\n",
    "    ahrs['qw'] = ahrs.apply(lambda row : get_qw(row['qx'], row['qy'], row['qz']), axis=1) \n",
    "    ahrs['rotMat'], ahrs['roll'], ahrs['pitch'], ahrs['yaw'] = convertQuat(ahrs)\n",
    "    ahrs = ahrs.drop(columns=['qw', 'qx', 'qy', 'qz'])\n",
    "    return ahrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceVector(ax,ay,az):\n",
    "    return np.array([ax,ay,az])\n",
    "\n",
    "def getLinearAccFromRawAcc(rotMatrix, rawAcc):\n",
    "    numRows = rotMatrix.shape[0]\n",
    "    linAcc_x, linAcc_y = [], []\n",
    "    for row in range(numRows):\n",
    "        linearAcceleration = (rotMatrix[row] @ rawAcc[row]) + gravity\n",
    "        linAcc_x.append(linearAcceleration[0])\n",
    "        linAcc_y.append(linearAcceleration[1])\n",
    "    return linAcc_x, linAcc_y\n",
    "\n",
    "def processAcceData(acceData, ahrsData):\n",
    "    acceData['ax_s'] = acceData['ax'].ewm(span=smoothSpan, adjust=True).mean()\n",
    "    acceData['ay_s'] = acceData['ay'].ewm(span=smoothSpan, adjust=True).mean()\n",
    "    acceData['az_s'] = acceData['az'].ewm(span=smoothSpan, adjust=True).mean()\n",
    "    acceData['acc'] = acceData.apply(lambda row : acceVector(row['ax_s'], row['ay_s'], row['az_s']), axis=1)\n",
    "    acceData['lin_ax'], acceData['lin_ay'] = getLinearAccFromRawAcc(ahrsData['rotMat'], acceData['acc'])\n",
    "    return acceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGyroData(gyroData):\n",
    "    gyroData['gz_s'] = gyroData['gz'].ewm(span=smoothSpan, adjust=True).mean()\n",
    "    return gyroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIMUData(acceData, gyroData, ahrsData):\n",
    "    ahrsData = processAHRSData(ahrsData);\n",
    "    acceData = processAcceData(acceData, ahrsData);\n",
    "    gyroData = processGyroData(gyroData);\n",
    "    imuData = pd.concat([acceData[['ts','lin_ax', 'lin_ay']], gyroData[['gz_s']], \\\n",
    "                         ahrsData[['roll', 'pitch', 'yaw']]], axis=1);\n",
    "    return imuData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathImuInput(imuData):\n",
    "    pathInitialTime = imuData['ts'].values[0]\n",
    "    ## 7 rows and 100 columns, each row represents each feature\n",
    "    pathImuInput = np.zeros((7, imuInputSequenceLength))\n",
    "    \n",
    "    ## calculating sampling frequency for path\n",
    "    numRowsInPath = imuData.shape[0]\n",
    "    samplingFactor = int(np.floor_divide(numRowsInPath, imuInputSequenceLength))\n",
    "\n",
    "    ## unix time to seconds\n",
    "    imuData['ts'] = (imuData['ts'] - pathInitialTime) / 1000.0    \n",
    "\n",
    "    ## new sampled timestamps\n",
    "    newTs = imuData['ts'].values[::samplingFactor][0:imuInputSequenceLength]\n",
    "    pathImuInput[0] = newTs\n",
    "    \n",
    "    ## fitting spline for each feature\n",
    "    for index,col in enumerate(['lin_ax', 'lin_ay', 'gz_s', 'roll', 'pitch', 'yaw']):\n",
    "        spl = splrep(imuData['ts'].values, imuData[col].values)\n",
    "        fitSpline = splev(newTs, spl)\n",
    "        pathImuInput[index+1] = fitSpline\n",
    "        \n",
    "    return pathImuInput, pathInitialTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSplineFitOutput(pathName, imuData, pathImuInput, saveFig=False):\n",
    "    fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(20, 20))\n",
    "    for index,col in enumerate(['lin_ax', 'lin_ay', 'gz_s', 'roll', 'pitch', 'yaw']):\n",
    "        axes[index].plot(imuData['ts'], imuData[col], label=f\"orig_{col}\")\n",
    "        axes[index].plot(pathImuInput[0], pathImuInput[index+1], label=f\"fit_{col}\")\n",
    "        axes[index].legend(loc='best')\n",
    "    if saveFig == True:\n",
    "        plt.savefig(f\"{pictureSaveDir}/{pathName}_splineFitOutput.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDecoderData(pathName, floorString):\n",
    "    ## output variables\n",
    "    decoderTs = np.zeros(wayPointMaxSequenceLength)\n",
    "    wayPointOutput = np.zeros((wayPointMaxSequenceLength, 3))\n",
    "\n",
    "    pathWayPointData = wayPointData_train[wayPointData_train.path == pathName].reset_index(drop=True)\n",
    "    numWaypoints = pathWayPointData.shape[0]    \n",
    "\n",
    "    ## get inference timestamps and store in decoderTs variable\n",
    "    inferenceTs = (pathWayPointData['timestamp'].values - pathInitialTime) / 1000.0\n",
    "    decoderTs[0:numWaypoints] = inferenceTs\n",
    "\n",
    "    ## get local position information\n",
    "    initialWayPoint = pathWayPointData.loc[0,['x', 'y']].values.astype(np.float64)\n",
    "    localWayPoints = pathWayPointData.loc[:, ['x','y']].values.astype(np.float64) - initialWayPoint\n",
    "\n",
    "    wayPointOutput[0:numWaypoints, 0:2] = localWayPoints\n",
    "    wayPointOutput[0:numWaypoints, 2] = floor_map[folder.name]\n",
    "\n",
    "    return decoderTs, wayPointOutput, numWaypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildingsList = generate_target_buildings()\n",
    "buildingsList = [buildingsList[0]] + buildingsList[2:]\n",
    "wayPointData_train = getWayPointData_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/109 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bdg = 5a0546857ecc773753327266 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109/109 [00:36<00:00,  3.02it/s]\n",
      "100%|██████████| 131/131 [00:36<00:00,  3.55it/s]\n",
      "100%|██████████| 110/110 [00:47<00:00,  2.30it/s]\n",
      "100%|██████████| 78/78 [00:24<00:00,  3.15it/s]\n",
      "100%|██████████| 86/86 [00:43<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "pathNameList = []\n",
    "buildingList = []\n",
    "encoderDataList = []\n",
    "decoderDataList = []\n",
    "inferenceTsList = []\n",
    "numWayPointsList = []\n",
    "\n",
    "for index,building in enumerate(buildingsList):\n",
    "    print(f\"{index+1} bdg = {building} -----------------\")\n",
    "    building_path = input_dir() / 'train' / building\n",
    "    folders = sorted(building_path.glob('*'))\n",
    "    ## print(f\"There are {len(list(folders))} floors in building\")   \n",
    "    \n",
    "    ## iterate through each floor \n",
    "    for folder in folders:\n",
    "        floorFiles = sorted(folder.glob(\"*.txt\"))\n",
    "        ## iterate through each path file\n",
    "        for pathFile in tqdm(floorFiles):\n",
    "            pathName = pathFile.name.split('.')[0]\n",
    "            acceData, gyroData, ahrsData = extract_IMUData(pathFile)\n",
    "\n",
    "            ## get encoder data from imu input\n",
    "            imuData = getIMUData(acceData, gyroData, ahrsData)\n",
    "            pathImuInput, pathInitialTime = getPathImuInput(imuData)\n",
    "            ## plotSplineFitOutput(pathName, imuData,pathImuInput, saveFig=False) \n",
    "            \n",
    "            ## get decoder data from waypoint data\n",
    "            inferenceTs, decoderInput, numWayPoints = getDecoderData(pathName, folder.name)\n",
    "\n",
    "            ## store output to list\n",
    "            pathNameList.append(pathName)\n",
    "            buildingList.append(building)\n",
    "            encoderDataList.append(pathImuInput)\n",
    "            decoderDataList.append(decoderInput)\n",
    "            inferenceTsList.append(inferenceTs)\n",
    "            numWayPointsList.append(numWayPoints)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imuDataOutput = pd.DataFrame()\n",
    "imuDataOutput['path'] = pathNameList\n",
    "imuDataOutput['building'] = buildingList\n",
    "imuDataOutput['encoderData'] = encoderDataList\n",
    "imuDataOutput['decoderData'] = decoderDataList\n",
    "imuDataOutput['inferenceTsList'] = inferenceTsList\n",
    "imuDataOutput['numWayPoints'] = numWayPointsList\n",
    "imuDataOutput.to_pickle(f\"imuSeq2SeqData.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>building</th>\n",
       "      <th>encoderData</th>\n",
       "      <th>decoderData</th>\n",
       "      <th>inferenceTsList</th>\n",
       "      <th>numWayPoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e15730aa280850006f3d005</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>[[0.0, 0.322, 0.645, 0.968, 1.291, 1.613, 1.93...</td>\n",
       "      <td>[[0.0, 0.0, -1.0], [1.365509033203125, 4.91879...</td>\n",
       "      <td>[-0.261, 9.859, 20.294, 31.007, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e15730b1506f2000638fc29</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>[[0.0, 0.222, 0.444, 0.666, 0.887, 1.109, 1.33...</td>\n",
       "      <td>[[0.0, 0.0, -1.0], [6.1605682373046875, -1.404...</td>\n",
       "      <td>[-0.119, 7.921, 19.09, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e15730ca280850006f3d007</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>[[0.0, 0.262, 0.524, 0.787, 1.049, 1.311, 1.57...</td>\n",
       "      <td>[[0.0, 0.0, -1.0], [-6.646209716796875, 0.5278...</td>\n",
       "      <td>[-0.112, 8.541, 15.752, 23.097, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e15730e1506f2000638fc2b</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>[[0.0, 0.363, 0.726, 1.089, 1.452, 1.816, 2.17...</td>\n",
       "      <td>[[0.0, 0.0, -1.0], [-5.328582763671875, 5.6999...</td>\n",
       "      <td>[-0.122, 8.202, 18.126, 26.743, 34.789, 0.0, 0...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e15730f1506f2000638fc2d</td>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>[[0.0, 0.161, 0.323, 0.484, 0.645, 0.807, 0.96...</td>\n",
       "      <td>[[0.0, 0.0, -1.0], [0.8319854736328125, 4.2953...</td>\n",
       "      <td>[-0.114, 7.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path                  building  \\\n",
       "0  5e15730aa280850006f3d005  5a0546857ecc773753327266   \n",
       "1  5e15730b1506f2000638fc29  5a0546857ecc773753327266   \n",
       "2  5e15730ca280850006f3d007  5a0546857ecc773753327266   \n",
       "3  5e15730e1506f2000638fc2b  5a0546857ecc773753327266   \n",
       "4  5e15730f1506f2000638fc2d  5a0546857ecc773753327266   \n",
       "\n",
       "                                         encoderData  \\\n",
       "0  [[0.0, 0.322, 0.645, 0.968, 1.291, 1.613, 1.93...   \n",
       "1  [[0.0, 0.222, 0.444, 0.666, 0.887, 1.109, 1.33...   \n",
       "2  [[0.0, 0.262, 0.524, 0.787, 1.049, 1.311, 1.57...   \n",
       "3  [[0.0, 0.363, 0.726, 1.089, 1.452, 1.816, 2.17...   \n",
       "4  [[0.0, 0.161, 0.323, 0.484, 0.645, 0.807, 0.96...   \n",
       "\n",
       "                                         decoderData  \\\n",
       "0  [[0.0, 0.0, -1.0], [1.365509033203125, 4.91879...   \n",
       "1  [[0.0, 0.0, -1.0], [6.1605682373046875, -1.404...   \n",
       "2  [[0.0, 0.0, -1.0], [-6.646209716796875, 0.5278...   \n",
       "3  [[0.0, 0.0, -1.0], [-5.328582763671875, 5.6999...   \n",
       "4  [[0.0, 0.0, -1.0], [0.8319854736328125, 4.2953...   \n",
       "\n",
       "                                     inferenceTsList  numWayPoints  \n",
       "0  [-0.261, 9.859, 20.294, 31.007, 0.0, 0.0, 0.0,...             4  \n",
       "1  [-0.119, 7.921, 19.09, 0.0, 0.0, 0.0, 0.0, 0.0...             3  \n",
       "2  [-0.112, 8.541, 15.752, 23.097, 0.0, 0.0, 0.0,...             4  \n",
       "3  [-0.122, 8.202, 18.126, 26.743, 34.789, 0.0, 0...             5  \n",
       "4  [-0.114, 7.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...             2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imuDataOutput.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
