{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import dask\n",
    "from dask.distributed import wait\n",
    "from dask.distributed import Client, wait, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46721</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>7.23 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:46721' processes=4 threads=4, memory=7.23 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set n_workers to number of cores\n",
    "client = Client(n_workers=multiprocessing.cpu_count(), threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_map = {\"B2\": -2, \"B1\": -1, \"F1\": 0, \"F2\": 1, \"F3\": 2, \"F4\": 3, \"F5\": 4, \"F6\": 5, \"F7\": 6, \"F8\": 7, \"F9\": 8,\n",
    "             \"1F\": 0, \"2F\": 1, \"3F\": 2, \"4F\": 3, \"5F\": 4, \"6F\": 5, \"7F\": 6, \"8F\": 7, \"9F\": 8}\n",
    "\n",
    "\n",
    "minCount = 1\n",
    "rssiFillerValue = -999.0\n",
    "dtFillerValue   = 1000.0\n",
    "freqFillerValue = 0\n",
    "outputDir = '.'\n",
    "sampleCsvPath = 'sample_submission.csv'\n",
    "buildingBssidPklFilePath = \"buildingBssids.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dir() -> Path:\n",
    "    return Path('.')\n",
    "\n",
    "def generate_target_buildings() -> List[str]:\n",
    "    ssubm = pd.read_csv(sampleCsvPath)\n",
    "    ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "    return sorted(ssubm_df[0].value_counts().index.tolist()) # type: ignore\n",
    "\n",
    "def extract_wps_wifis(file: Path) -> Tuple[List[str], List[str]]:\n",
    "    wps = []\n",
    "    wifis = []\n",
    "    with open(file) as f:\n",
    "        for row in csv.reader(f, delimiter=\"\\t\", doublequote=True):\n",
    "            if row[1] == \"TYPE_WAYPOINT\":\n",
    "                # x\n",
    "                row[2] = float(row[2])  # type: ignore\n",
    "                # y\n",
    "                row[3] = float(row[3])  # type: ignore\n",
    "                wps.append([int(row[0]), row[2], row[3]])\n",
    "            elif row[1] == \"TYPE_WIFI\":\n",
    "                # wifi signal value\n",
    "                row[4] = int(row[4])  # type: ignore\n",
    "                wifis.append(row)\n",
    "    wps = sorted(wps, key=lambda x: x[0])  # timestamp\n",
    "    wifis = sorted(wifis, key=lambda x: x[0])  # timestamp\n",
    "    return wps, wifis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFloorBssids_train(building : str):\n",
    "    \"\"\"\n",
    "    for a given building in train set, this function calculates\n",
    "    the unique wifi bssids within each floor\n",
    "    \n",
    "    returns :  a dict with keys = {building}_{floor}, values = list(set(floorBssids))\n",
    "    \"\"\"\n",
    "    building_path = input_dir() / 'train' / building\n",
    "    floorBssids = {}\n",
    "    folders = sorted(building_path.glob('*'))\n",
    "    for folder in folders:\n",
    "        folderData = []\n",
    "        files = folder.glob(\"*.txt\")\n",
    "        for file in files:\n",
    "            _, wifiData = extract_wps_wifis(file)\n",
    "            folderData.extend([t[3] for t in wifiData])\n",
    "        floorBssids[f\"{folder.name}\"] = list(set(folderData))\n",
    "    return floorBssids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateIntersectingBssids(floorBssids):\n",
    "    \"\"\"\n",
    "    given a dict with floor -> bssid list mapping,\n",
    "    returns : list of bssids which occur in more than 1 floor \n",
    "    \"\"\"\n",
    "    commonBssids = []\n",
    "    for k1, v1 in floorBssids.items():\n",
    "        for k2, v2 in floorBssids.items():\n",
    "            if (k1 != k2):\n",
    "                intersectingBssids = list(set(v1).intersection(set(v2)))\n",
    "                commonBssids.extend(intersectingBssids)\n",
    "    return commonBssids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBssidsInfo(floorBssids):\n",
    "    \"\"\"\n",
    "    given a dict with floor -> bssid list mapping,m\n",
    "    Function calcuates total number of bssids and number \n",
    "    of unique bssids and prints result\n",
    "    \"\"\"\n",
    "    totalBssids = []\n",
    "    for k,v in floorBssids.items():\n",
    "        ## print(f\"{k} has {len(v)} total bssids\")\n",
    "        totalBssids.extend(v)\n",
    "    \n",
    "    print(f\"Totally, There are {len(totalBssids)} bssids\")\n",
    "    print(f\"There are {len(set(totalBssids))} unique bssids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateUniqueFloorBssids(floorBssids, commonBssids):\n",
    "    \"\"\"\n",
    "    floorBssids : a dict with floor -> bssid list mapping\n",
    "    commonBssids : list of bssids which are present in more than one floor\n",
    "    \"\"\"\n",
    "    uniqueFloorBssids = {}\n",
    "    for k,v in floorBssids.items():\n",
    "        uniqueFloorBssids[k] = list(set(v) - set(commonBssids))    \n",
    "    return uniqueFloorBssids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFloorUniqueBssidData(buildingsList):\n",
    "    floorUniqueBssidData = {}\n",
    "    for building in buildingsList:\n",
    "        floorBssids = generateFloorBssids_train(building)    # consumes most time\n",
    "        commonBssids = generateIntersectingBssids(floorBssids)\n",
    "        uniqueBssids = generateUniqueFloorBssids(floorBssids, commonBssids)\n",
    "\n",
    "        print(building)\n",
    "        print(f\"building unique bssids information\")\n",
    "        printBssidsInfo(floorBssids)\n",
    "        print(f\"Floor unique bssids information\")\n",
    "        printBssidsInfo(uniqueBssids)\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        floorUniqueBssidData[building] = uniqueBssids\n",
    "    \n",
    "    with open(\"floorUniqueBssidData.json\", \"w\") as outfile: \n",
    "        json.dump(floorUniqueBssidData, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wifiAPFloorMapping:\n",
    "    def __init__(self, building, floorUniqueBssidMapPath):\n",
    "        self.building = building\n",
    "        self.floorList = self.getBuildingFloorList()\n",
    "        self.uniqueBssidsMap = self.getFloorUniqueBssids(floorUniqueBssidMapPath)\n",
    "        self.outputData = self.generateOutputData()\n",
    "    \n",
    "    def getFloorUniqueBssids(self, floorUniqueBssidMapPath):\n",
    "        with open(floorUniqueBssidMapPath, \"r\") as infile:\n",
    "            floorUniqueBssidMap = json.load(infile)\n",
    "        return floorUniqueBssidMap.get(self.building, None)\n",
    "    \n",
    "    def getBuildingFloorList(self):\n",
    "        buildingPath = input_dir() / 'train' / self.building\n",
    "        folders = sorted(buildingPath.glob('*'))\n",
    "        return [folder.name for folder in folders] + ['common']\n",
    "\n",
    "    def generateOutputData(self):\n",
    "        outputData = {'pathName' : []}\n",
    "        for floor in self.floorList:\n",
    "            outputData[f\"{floor}_count\"] = []\n",
    "            outputData[f\"{floor}_mean\"]  = []\n",
    "            outputData[f\"{floor}_median\"]  = []\n",
    "        return outputData\n",
    "    \n",
    "    def findMappingFloor(self, wifiAp):\n",
    "        matchingfloor = 'common'\n",
    "        if self.uniqueBssidsMap is not None:\n",
    "            for floor, floorAPList in self.uniqueBssidsMap.items():\n",
    "                if wifiAp in floorAPList:\n",
    "                    matchingfloor = floor\n",
    "                    break\n",
    "        return matchingfloor \n",
    "    \n",
    "    def getPathFileWiFiData(self, file):\n",
    "        _, wifiData = extract_wps_wifis(file)\n",
    "        wifiData = pd.DataFrame(wifiData, columns = ['timestamp','type','ssid', 'bssid', 'rssi', 'freq', 'last_ts'])\n",
    "        wifiData.drop(labels=['timestamp', 'type', 'ssid', 'freq', 'last_ts'], axis=1, inplace=True)\n",
    "        wifiData['mappedFloor'] = wifiData['bssid'].apply(self.findMappingFloor)\n",
    "        return wifiData\n",
    "        \n",
    "    def updatePathFileToOutput(self, file):\n",
    "        # add path file to output\n",
    "        self.outputData['pathName'].append(file.name.split('.')[0])\n",
    "        \n",
    "        # create wifi data of pathfile\n",
    "        wifiData = self.getPathFileWiFiData(file)\n",
    "        \n",
    "        # shortlist wifi bssids based on each floor list\n",
    "        for floor in self.floorList:\n",
    "            rssiData = wifiData[wifiData['mappedFloor']== floor]['rssi'].values\n",
    "            if len(rssiData) > 0:\n",
    "                mean, median = np.mean(rssiData), np.median(rssiData)\n",
    "            else:\n",
    "                mean, median = 0.0, 0.0\n",
    "                \n",
    "            self.outputData[f\"{floor}_count\"].append(len(rssiData))\n",
    "            self.outputData[f\"{floor}_mean\"].append(mean)\n",
    "            self.outputData[f\"{floor}_median\"].append(median)\n",
    "        del wifiData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildingsList = generate_target_buildings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "building_path = input_dir() / 'test'\n",
    "# output placeholder\n",
    "testPathFloorPredictions = { 'building' : [], 'pathName' : [], 'predFloor':[] }\n",
    "\n",
    "for building in tqdm(buildingsList):\n",
    "    buildingTestPathFiles = ssubm_df[ssubm_df[0] == building][1].unique()\n",
    "    #print(f\"There are {len(buildingTestPathFiles)} test path files in building\")\n",
    "    \n",
    "    temp = wifiAPFloorMapping(building, 'floorUniqueBssidData.json')\n",
    "    for testPathFile in buildingTestPathFiles:\n",
    "        temp.updatePathFileToOutput(building_path / f\"{testPathFile}.txt\")  \n",
    "    \n",
    "    outputDf = pd.DataFrame(temp.outputData)\n",
    "    totalColumns = list(set(temp.floorList) - set(['common']))\n",
    "    columnsOfInterest = [f\"{x}_count\" for x in totalColumns]\n",
    "    \n",
    "    # taking the maximum count as floor prediction\n",
    "    outputDf['predFloor'] = pd.Series([totalColumns[idx] for idx in outputDf[columnsOfInterest].values.argmax(axis=1)]).map(floor_map)\n",
    "    \n",
    "    # write to output variable\n",
    "    testPathFloorPredictions['pathName'].extend(outputDf['pathName'].values.tolist())\n",
    "    testPathFloorPredictions['predFloor'].extend(outputDf['predFloor'].values.tolist())\n",
    "    testPathFloorPredictions['building'].extend([building] * outputDf.shape[0])    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "testPathFloorPredictions = pd.DataFrame(testPathFloorPredictions)\n",
    "testPathFloorPredictions.to_csv('testPathFloorPredictions.csv',index=False)\n",
    "testPathFloorPredictions.head(3)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathFloorMapping(inputPath, csvMap):\n",
    "    return int(csvMap[csvMap['pathName']== inputPath]['predFloor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read submission csv file and apply our floor mappings to it\n",
    "ssubm = pd.read_csv(sampleCsvPath)\n",
    "ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "ownCsv = pd.read_csv('testPathFloor_Mapping.csv')\n",
    "ssubm_df['floor'] = ssubm_df[1].apply(pathFloorMapping, csvMap=ownCsv)\n",
    "ssubm_df['site_path_timestamp'] = ssubm_df[0].astype(str) + '_' + ssubm_df[1].astype(str) + '_' + ssubm_df[2].astype(str) \n",
    "ssubm_df.to_csv('testFloorPredictionsSubmssion.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>floor</th>\n",
       "      <th>site_path_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>046cfa46be49fc10834815c6</td>\n",
       "      <td>0000000000009</td>\n",
       "      <td>0</td>\n",
       "      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>046cfa46be49fc10834815c6</td>\n",
       "      <td>0000000009017</td>\n",
       "      <td>0</td>\n",
       "      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a0546857ecc773753327266</td>\n",
       "      <td>046cfa46be49fc10834815c6</td>\n",
       "      <td>0000000015326</td>\n",
       "      <td>0</td>\n",
       "      <td>5a0546857ecc773753327266_046cfa46be49fc1083481...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                         1              2  floor  \\\n",
       "0  5a0546857ecc773753327266  046cfa46be49fc10834815c6  0000000000009      0   \n",
       "1  5a0546857ecc773753327266  046cfa46be49fc10834815c6  0000000009017      0   \n",
       "2  5a0546857ecc773753327266  046cfa46be49fc10834815c6  0000000015326      0   \n",
       "\n",
       "                                 site_path_timestamp  \n",
       "0  5a0546857ecc773753327266_046cfa46be49fc1083481...  \n",
       "1  5a0546857ecc773753327266_046cfa46be49fc1083481...  \n",
       "2  5a0546857ecc773753327266_046cfa46be49fc1083481...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssubm_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCsv = pd.read_csv('referencePublicNotebooks/99%_floorPredictionss_submission.csv')\n",
    "matchingRows = (inputCsv['site_path_timestamp'] == ssubm_df['site_path_timestamp']).all()\n",
    "\n",
    "if matchingRows == True:\n",
    "    inputCsv['floor'] = ssubm_df['floor']\n",
    "    inputCsv.to_csv('outputSubmission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
